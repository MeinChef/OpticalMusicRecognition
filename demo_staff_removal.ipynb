{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa52fe0",
   "metadata": {},
   "source": [
    "# Optical Music Recognition - Staff Removal\n",
    "In this Notebook we are going to download the CVC Muscima Dataset, and try to do staff removal, using the ground truth provided in the dataset.\n",
    "We are going to use Tensorflow as our backend. \n",
    "\n",
    "## What is Staff Removal?\n",
    "Staff Removal is one of the very early steps of preprocessing music scores. The task is to remove the horizontal lines that usually indicate the pitch. Without the staff lines, the classification of symbols (notes, clefs, rests) may be easier. It also might be easier to isolate the symbols, as they are not connected by lines anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6be453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience Functions\n",
    "\n",
    "# For sanity Checking of the Hyperparams in cfg make sense\n",
    "def find_largest_image_resolution(root, valid_extensions = [\".png\"]):\n",
    "    max_resolution = (0, 0)\n",
    "    max_image_path = None\n",
    "\n",
    "    folder_paths = os.listdir(root)\n",
    "    # probably mac residuals, not a folder\n",
    "    folder_paths = remove_macos(folder_paths)\n",
    "\n",
    "    for folder_path in folder_paths:\n",
    "        for root, _, files in os.walk(os.path.join(root, folder_path)):\n",
    "            for file in files:\n",
    "                if os.path.splitext(file)[1].lower() in valid_extensions:\n",
    "                    image_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        with Image.open(image_path) as img:\n",
    "                            width, height = img.size\n",
    "                            if width * height > max_resolution[0] * max_resolution[1]:\n",
    "                                max_resolution = (width, height)\n",
    "                                max_image_path = image_path\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {image_path}: {e}\")\n",
    "\n",
    "    return max_resolution, max_image_path\n",
    "\n",
    "# Helper function to remove residuals from zipping\n",
    "def remove_macos(dir_cont: list) -> list:\n",
    "    if \".DS_Store\" in dir_cont:\n",
    "        dir_cont.remove(\".DS_Store\")\n",
    "    return dir_cont\n",
    "\n",
    "# Directory crawler for creating data/target file paths.\n",
    "def crawler(data_root: str = \"data\", target_root: str = \"target\") -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    data_dir = remove_macos(\n",
    "        sorted(\n",
    "            os.listdir(data_root)\n",
    "        )\n",
    "    )\n",
    "    target_dir = remove_macos(\n",
    "        sorted(\n",
    "            os.listdir(target_root)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    data = []\n",
    "    targets = []\n",
    "\n",
    "    if not (data_dir == target_dir):\n",
    "        raise ValueError(f\"Content of the directories not identical.\\nContent of Data: {data_dir}\\nContent of Target: {target_dir}\")\n",
    "    \n",
    "    for dir in data_dir:\n",
    "        if os.path.isdir(os.path.join(data_root, dir)) and os.path.isdir(os.path.join(target_root, dir)):\n",
    "            # grab the contents of both directories\n",
    "            data_dir_cont = remove_macos(\n",
    "                sorted(\n",
    "                    os.listdir(\n",
    "                        os.path.join(data_root, dir)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            target_dir_cont = remove_macos(\n",
    "                sorted(\n",
    "                    os.listdir(\n",
    "                        os.path.join(target_root, dir)\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if data_dir_cont == target_dir_cont:\n",
    "\n",
    "                # extend the file names to full paths\n",
    "                data_dir_cont = [\n",
    "                    os.path.join(data_root, dir, file) for file in data_dir_cont\n",
    "                ]\n",
    "\n",
    "                target_dir_cont = [\n",
    "                    os.path.join(target_root, dir, file) for file in target_dir_cont\n",
    "                ]\n",
    "\n",
    "                data.extend(data_dir_cont)\n",
    "                targets.extend(target_dir_cont)\n",
    "                \n",
    "            else:\n",
    "                raise Exception(f\"Contents of data and target do not match.\\nData: {data_dir_cont}\\nTarget: {target_dir_cont}\")\n",
    "        else:\n",
    "            raise Exception(f\"Not a directory: {dir} in {data_root}.\")\n",
    "    \n",
    "    return tf.convert_to_tensor(data, dtype = tf.string), tf.convert_to_tensor(targets, dtype = tf.string)\n",
    "\n",
    "\n",
    "def visualize_images(\n",
    "        images, \n",
    "        titles = None, \n",
    "        vmin = -1, \n",
    "        vmax = 1\n",
    "    ):\n",
    "\n",
    "    n = len(images)\n",
    "    titles = titles or [f\"Image {i+1}\" for i in range(n)]\n",
    "\n",
    "    fig, ax = plt.subplots(1, n, figsize = (5 * n, 5))\n",
    "\n",
    "    if n == 1:\n",
    "        ax = [ax]  # ensure ax is iterable\n",
    "\n",
    "    for i, (img, axis) in enumerate(zip(images, ax)):\n",
    "        # Convert to numpy and squeeze singleton dims\n",
    "        img = tf.squeeze(img)\n",
    "        img = img.numpy() if isinstance(img, tf.Tensor) else img\n",
    "\n",
    "        axis.imshow(img, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        axis.set_title(titles[i])\n",
    "        axis.axis('off')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60727d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downalad an unzip dataset\n",
    "def download_extract_zip(filename, extract_to):\n",
    "    try:\n",
    "        url = \"http://datasets.cvc.uab.es/muscima/CVCMUSCIMA_WI.zip\"\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Download with progress bar\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        if os.path.exists(filename) and os.path.getsize(filename) >= 984118102:\n",
    "            print(\"File exists and is of correct size (or bigger)\")\n",
    "        else:\n",
    "            with open(filename, 'wb') as f, tqdm(\n",
    "                desc = f\"Downloading {filename}\",\n",
    "                total = total_size,\n",
    "                unit = 'B',\n",
    "                unit_scale = True,\n",
    "                unit_divisor = 1024,\n",
    "            ) as bar:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        bar.update(len(chunk))\n",
    "            print(f\"Downloaded {filename}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {filename}: {e}\")\n",
    "        \n",
    "        \n",
    "    # Check if the folder already exists, and create it if not\n",
    "    if not os.path.exists(extract_to) or not os.path.isdir(extract_to):\n",
    "        os.makedirs(extract_to)\n",
    "        print(f\"Created directory {extract_to}.\")\n",
    "\n",
    "\n",
    "    # Extract only if the files are not already present\n",
    "    if not (\"PNG_GT_Gray\" and \"PNG_GT_NoStaff\") in os.listdir(extract_to):\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_to)\n",
    "        print(f\"Extracted {filename} to {extract_to}.\")\n",
    "    \n",
    "        # Make folder structure more accessible\n",
    "        for filename in os.listdir(os.path.join(extract_to, 'CVCMUSCIMA_WI')):\n",
    "            shutil.move(\n",
    "                os.path.join(extract_to, 'CVCMUSCIMA_WI', filename),\n",
    "                os.path.join(extract_to, filename)\n",
    "            )\n",
    "        os.rmdir(os.path.join(extract_to, 'CVCMUSCIMA_WI'))\n",
    "        print(f\"Moved files from {os.path.join(extract_to, 'CVCMUSCIMA_WI')} to {extract_to} and removed the empty directory.\")\n",
    "\n",
    "        # We want to train on Grayscale Images, not on Black/White\n",
    "        shutil.rmtree(\n",
    "            os.path.join(\n",
    "                extract_to,\n",
    "                \"PNG_GT_BW\"\n",
    "                )\n",
    "            )  \n",
    "        print(f\"Removed {os.path.join(extract_to, 'PNG_GT_BW')} directory and its contents.\")\n",
    "\n",
    "@tf.function\n",
    "def load_and_preprocess(\n",
    "        data_path: tf.Tensor, \n",
    "        target_path: tf.Tensor,\n",
    "        width: int = 1280,\n",
    "        height: int = 720\n",
    "    ):\n",
    "    # Read and decode images\n",
    "    data_img = tf.io.read_file(data_path)\n",
    "    data_img = tf.io.decode_png(\n",
    "        contents = data_img,\n",
    "        channels = 1,\n",
    "        dtype = tf.uint8\n",
    "    )\n",
    "    # Invert, since resice_with_pad fills pad with 0s\n",
    "    data_img = tf.uint8.max - data_img\n",
    "    \n",
    "    # No Inversion of target, since the file is 0 (background) and 255 (Notes)\n",
    "    target_img = tf.io.read_file(target_path)\n",
    "    target_img = tf.io.decode_png(\n",
    "        contents = target_img, \n",
    "        channels = 1,\n",
    "        dtype = tf.uint8\n",
    "    )\n",
    "\n",
    "    # Resize\n",
    "    data_img = tf.image.resize_with_pad(\n",
    "        image = data_img,\n",
    "        target_height = height,\n",
    "        target_width = width,\n",
    "        # Not using Anti-Aliasing makes the model perform worse \n",
    "        # and the input image a lot more incoherent \n",
    "        antialias = True\n",
    "        )\n",
    "    # Revert\n",
    "    data_img = tf.uint8.max - data_img\n",
    "\n",
    "    target_img = tf.image.resize_with_pad(\n",
    "        image = target_img,\n",
    "        target_height = height,\n",
    "        target_width = width,\n",
    "        antialias = True\n",
    "        )\n",
    "    # And make target similar to Data (255 = Background)\n",
    "    target_img = tf.uint8.max - target_img\n",
    "\n",
    "    data_img = tf.cast(\n",
    "        x = data_img, \n",
    "        dtype = tf.float32\n",
    "        )\n",
    "    target_img = tf.cast(\n",
    "        x = target_img,\n",
    "        dtype = tf.float32\n",
    "    )\n",
    "\n",
    "    # Shift to [-1, 1]\n",
    "    data_img = data_img / 127.5 - 1\n",
    "    target_img = target_img / 127.5 - 1\n",
    "\n",
    "    return data_img, target_img\n",
    "\n",
    "def create_dataset(\n",
    "        data_paths: tf.Tensor, \n",
    "        target_paths: tf.Tensor, \n",
    "        img_width: int = 1280,\n",
    "        img_height: int = 720,\n",
    "    ) -> tf.data.Dataset:\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data_paths, target_paths))\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        lambda x, y: load_and_preprocess(\n",
    "                data_path = x, \n",
    "                target_path = y, \n",
    "                width = img_width, \n",
    "                height = img_height\n",
    "            ),\n",
    "        num_parallel_calls = tf.data.AUTOTUNE\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e467e7",
   "metadata": {},
   "source": [
    "## Define Hyperparameter\n",
    "The image resolution, and the low batch size are stemming from my low-VRAM (8GB) GPU. Adjust these to make it better on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d21879",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"path\": \"data\",\n",
    "    \"img_width\": int(3479 / 4),\n",
    "    \"img_height\": int(2466 / 4),\n",
    "    \"batch\": 8,\n",
    "    \"shuffle_buffer\": 2,\n",
    "    \"epochs\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf03ab0",
   "metadata": {},
   "source": [
    "## Downloading the dataset\n",
    "In this task we are going to use the CVC-Muscima dataset. After downloading it from the [Autonomous University of Barcelona](http://datasets.cvc.uab.es/muscima/CVCMUSCIMA_WI.zip), the dataset will be present as `cvc.zip`. The function `download_extract_zip()` will thereafter extract it to a new folder `./data`, and then shuffle some files around.\n",
    "\n",
    "If the download fails, you can download it manually, put it in the same folder as this notebook and execute the `download_extract_zip()`, passing the filename as it is on your system as first parameter. The function will recognize the file and unzip it, and ensure proper folder structure for the rest of the code.\n",
    "\n",
    "### Regarding Splits\n",
    "Standard would be splitting the dataset into training and testing - if not also validation - sets. However, this requires to load the full dataset into memory, and this is not possible on many systems with low to mid (maybe even high) capacity (tested with 32GB). This is mainly because the images are pretty high-resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75758c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the dataset\n",
    "download_extract_zip(\"cvc.zip\", \"data\")\n",
    "\n",
    "# Checking if our image dimensions make sense\n",
    "print(find_largest_image_resolution(\"data/PNG_GT_Gray\"))\n",
    "# Sanity Check, should equal the other\n",
    "print(find_largest_image_resolution(\"data/PNG_GT_NoStaff\"))\n",
    "\n",
    "data, target = crawler(\n",
    "        data_root = os.path.join(\"data\", \"PNG_GT_Gray\"),\n",
    "        target_root = os.path.join(\"data\", \"PNG_GT_NoStaff\")\n",
    "    )\n",
    "ds = create_dataset(\n",
    "    data_paths = data,\n",
    "    target_paths = target,\n",
    "    img_width = cfg[\"img_width\"],\n",
    "    img_height = cfg[\"img_height\"],\n",
    ")\n",
    "\n",
    "ds = ds.shuffle(cfg[\"shuffle_buffer\"]).batch(cfg[\"batch\"]).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba40b6",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "Below a Model with 3 CNN layers is defined. To see how it would look like with e.g. a fourth layer, uncomment the code. \\\n",
    "The decreasing kernel size with increasing network depth is inspired by https://doi.org/10.1007/978-3-319-58838-4_31. Or paper [51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbf3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(\n",
    "    shape = (cfg[\"img_height\"], cfg[\"img_width\"],1),\n",
    "    batch_size = cfg[\"batch\"],\n",
    "    dtype = tf.float32\n",
    "    )\n",
    "x = keras.layers.Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = 15,\n",
    "        strides = 1,\n",
    "        padding = \"same\",\n",
    "        activation = \"tanh\"\n",
    "    )(inputs)\n",
    "# x = keras.layers.Conv2D(\n",
    "#         filters = 32,\n",
    "#         kernel_size = 5,\n",
    "#         strides = 1,\n",
    "#         padding = \"same\",\n",
    "#         activation = \"tanh\"\n",
    "#     )(x)\n",
    "x = keras.layers.Conv2D(\n",
    "        filters = 16,\n",
    "        kernel_size = 5,\n",
    "        strides = 1,\n",
    "        padding = \"same\",\n",
    "        activation = \"tanh\"\n",
    "    )(x)\n",
    "out = keras.layers.Conv2D(\n",
    "        filters = 1,\n",
    "        kernel_size = 3,\n",
    "        strides = 1,\n",
    "        padding = \"same\",\n",
    "        activation = \"tanh\"\n",
    "    )(x)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = inputs,\n",
    "    outputs = out\n",
    ")\n",
    "model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"mse\",\n",
    "    # metrics = [\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed451a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds, epochs = cfg[\"epochs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758897e",
   "metadata": {},
   "source": [
    "Let us take a look on how good our model is by now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a30740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in ds.take(1):\n",
    "    pred = model(x)\n",
    "    visualize_images(\n",
    "        images = [x[0], pred[0], y[0]],\n",
    "        titles = [\"Original\", \"Prediction\", \"Target\"]\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
